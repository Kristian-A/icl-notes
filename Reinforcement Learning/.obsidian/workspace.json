{
  "main": {
    "id": "d5f78466838136eb",
    "type": "split",
    "children": [
      {
        "id": "92045314623a9d8a",
        "type": "tabs",
        "children": [
          {
            "id": "ad1cbbeedfd1555d",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "1. Markov Process.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "d59a438a0695698f",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "2. Markov Reward Process.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "afb82e536d8eb708",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "3. Markov Decision Process.md",
                "mode": "source",
                "source": false
              }
            }
          }
        ],
        "currentTab": 1
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "6d7c2e345fc216a6",
    "type": "split",
    "children": [
      {
        "id": "257f3b583230dce4",
        "type": "tabs",
        "children": [
          {
            "id": "75eb7b4e6f1317ba",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical"
              }
            }
          },
          {
            "id": "6083bb19fed20d97",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              }
            }
          },
          {
            "id": "87a55335f05882c4",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {}
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300
  },
  "right": {
    "id": "b791824900a2e674",
    "type": "split",
    "children": [
      {
        "id": "f41b3e046f9d3d3c",
        "type": "tabs",
        "children": [
          {
            "id": "772b5c746625606e",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "2. Markov Reward Process.md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "aa11191937399303",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "2. Markov Reward Process.md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "0dfa2b8449cef8dc",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              }
            }
          },
          {
            "id": "c3824bbe60f21a7e",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "2. Markov Reward Process.md"
              }
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300,
    "collapsed": true
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false
    }
  },
  "active": "d59a438a0695698f",
  "lastOpenFiles": [
    "1. Markov Process.md",
    "3. Markov Decision Process.md",
    "2. Markov Reward Process.md",
    "Pasted image 20231012213308.png"
  ]
}